# Blogposts I should read:

## NODE

~~[Understanding Neural ODE's - Jonty Sinai](https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html)~~ - Great!

[Neural Ordinary Differential Equations and Adversarial Attacks - rajatvd](https://rajatvd.github.io/Neural-ODE-Adversarial)

## Probability

[Probability Part 1: Probability for Everyone - Jonty Sinai](https://jontysinai.github.io/jekyll/update/2017/11/23/probability-for-everyone.html)

[Probability Part 2: Conditional Probability - Jonty Sinai](https://jontysinai.github.io/jekyll/update/2018/12/23/probability-part-two-conditional-probability.html)

[KL Divergence - Will Kurt ](<https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained>)

[A Statistical View of Deep Learning - Shakir Mohamed](<http://blog.shakirm.com/wp-content/uploads/2015/07/SVDL.pdf>)

## Variational Auto Encoders

~~[What is wrong with VAEs?](http://akosiorek.github.io/ml/2018/03/14/what_is_wrong_with_vaes.html)~~ - Nice explanation, mathematical. didn't read the "what's wrong", just the introduction.

~~[Variational Autoencoders Explained - Kevin Frans](<http://kvfrans.com/variational-autoencoders-explained/>)~~ - Shallow, good for intuition

[Tutorial on variational autoencoders - Carl Doersch](<https://arxiv.org/pdf/1606.05908.pdf>)

## Backpropogation

[Yes you should understand backprop - Andrej Karpathy](<https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b>)

~~[Backprop is not just the chain rule - Tim Vieira](<https://timvieira.github.io/blog/post/2017/08/18/backprop-is-not-just-the-chain-rule/>)~~ - Nice!

## Information theory

`[Visual Information Theory - Olah](http://colah.github.io/posts/2015-09-Visual-Information)

## Representation theory

[Neural Networks, Manifolds, and Topology  -Olah](<https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/>)

# Talks

[Towards a theoretical understanding of deep neural networks](https://youtu.be/rcR6P5O8CpU?t=4197)